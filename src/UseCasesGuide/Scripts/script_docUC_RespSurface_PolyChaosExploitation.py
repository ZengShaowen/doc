from __future__ import print_function
from openturns import *


# Create a function R^n --> R^p
# For example R^4 --> R
myModel = NumericalMathFunction(
    ['x1', 'x2', 'x3', 'x4'], ['y'], ['1+x1*x2 + 2*x3^2+x4^4'])

# Create a distribution of dimension n
# for example n=3 with indpendent components
Xdist = ComposedDistribution(
    [Normal(), Uniform(), Gamma(2.75, 1.0), Beta(2.5, 3.5, -1.0, 2.0)])

#############################################################
# STEP 1 : Construction of the multivariate orthonormal basis
#############################################################

# Dimension of the input random vector
dim = 4

# Create the univariate polynomial family collection
polyColl = PolynomialFamilyCollection(dim)
# For information, with the Krawtchouk and Charlier families :
polyColl[0] = KrawtchoukFactory()
polyColl[1] = CharlierFactory()
# for information, with the automatic selection
for i in range(Xdist.getDimension()):
    polyColl[i] = StandardDistributionPolynomialFactory(Xdist.getMarginal(i))
# which regroups the polynomial families for each direction
polyColl = PolynomialFamilyCollection(dim)
polyColl[0] = HermiteFactory()
polyColl[1] = LegendreFactory()
polyColl[2] = LaguerreFactory(2.75, 1)
# Parameter for the Jacobi factory : 'Probabilty' encoded with 1
polyColl[3] = JacobiFactory(2.5, 3.5, 1)


# Create the enumeration function
# LinearEnumerateFunction
enumerateFunction = LinearEnumerateFunction(dim)
# HyperbolicAnisotropicEnumerateFunction
q = 0.4
enumerateFunction = HyperbolicAnisotropicEnumerateFunction(dim, q)

# Create the multivariate orthonormal basis
# which is the the cartesian product of the univariate basis
multivariateBasis = OrthogonalProductPolynomialFactory(
    polyColl, enumerateFunction)


####################################################################
# STEP 2 : Truncature strategy of the multivariate orthonormal basis
#############################################################

# FixedStrategy :
# all the polynomials af degree <=2
# which corresponds to the 15 first ones
p = 15
truncatureBasisStrategy = FixedStrategy(multivariateBasis, p)


################################################################
# STEP 3 : Evaluation strategy of the approximation coefficients
#############################################################

sampleSize = 100
# This is the algorithm that generates a sequence of basis using Least
# Angle Regression
basisSequenceFactory = LAR()
# This algorithm estimates the empirical error on each sub-basis using
# Leave One Out strategy
fittingAlgorithm = CorrectedLeaveOneOut()
# Finally the metamodel selection algorithm embbeded in LeastSquaresStrategy
approximationAlgorithm = LeastSquaresMetaModelSelectionFactory(
    basisSequenceFactory, fittingAlgorithm)
evaluationCoeffStrategy = LeastSquaresStrategy(
    MonteCarloExperiment(sampleSize), approximationAlgorithm)


#####################################################
# STEP 4 : Creation of the Functional Chaos Algorithm
#############################################################
# FunctionalChaosAlgorithm :
# combination of the model : myModel
# the distribution of the input random vector : Xdist
# the truncature strategy of the multivariate basis
# and the evaluation strategy of the coefficients
polynomialChaosAlgorithm = FunctionalChaosAlgorithm(
    myModel, Xdist, truncatureBasisStrategy, evaluationCoeffStrategy)

# BEGIN_TEX
#####################################################
# Perform the simulation
#####################################################
polynomialChaosAlgorithm.run()

# Stream out the result
result = polynomialChaosAlgorithm.getResult()

# Get the polynomial chaos coefficients
# All the coefficients
coefficients = result.getCoefficients()

# The coefficients of marginal i
i = 1
coefficientsMarginal_i = result.getCoefficients()[i]

# Get the indices of the selected polynomials : K
subsetK = result.getIndices()

# Get the composition of the polynomials
# of the truncated multivariate basis
for i in range(subsetK.getSize()):
    print("Polynomial number ", i, " in truncated basis <-> polynomial number ",
          subsetK[i], " = ", LinearEnumerateFunction(dim)(subsetK[i]), " in complete basis")

# Get the multivariate basis
# as a colletion of NumericalMathFunction
functionCollection = result.getReducedBasis()

# Get the orthogonal basis
orthgBasis = result.getOrthogonalBasis()

# Get the distribution of variables Z
mu = orthgBasis.getMeasure()

# Get the composed model which is the model of the reduced variables Z
composedModel = result.getComposedModel()

# Get the composed meta model which is the model of the reduced variables Z
# within the reduced polynomials basis
composedMetaModel = result.getComposedMetaModel()

# Get the meta model which is the composed meta model combined with the
# iso probabilistic transformation
metaModel = result.getMetaModel()

# Get the projection strategy
myProjStat = polynomialChaosAlgorithm.getProjectionStrategy()
# END_TEX
